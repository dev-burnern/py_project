[프로젝트 보고서]

프로젝트명: 카카오톡 대화 분석 및 호감도 추론 PC 애플리케이션
제출일: 2024년 12월 5일
작성자: (학번/이름 기재)


1. 서론 (Introduction)


1.1 주제 선정 배경
현대 사회에서 비대면 소통의 비중이 급격히 증가함에 따라, 텍스트 기반 메신저(카카오톡 등)는 단순한 정보 전달 수단을 넘어 인간관계를 형성하고 유지하는 핵심 매체가 되었습니다. 특히 연인이나 썸(Some) 관계에 있는 남녀 사이의 대화에는 서로에 대한 호감도, 관심사, 감정 상태가 은연중에 드러납니다.
하지만 수개월, 수년에 걸쳐 축적된 수만 건의 대화 데이터를 개인이 직접 읽고 분석하는 것은 불가능에 가깝습니다. 기존의 분석 서비스들은 대부분 웹 기반으로 동작하여, 지극히 사적인 대화 내용이 외부 서버로 전송된다는 보안상의 불안감을 사용자에게 주었습니다.
이에 본 프로젝트는 "내 컴퓨터에서 안전하게 실행되는 분석기"를 모토로, 텍스트 마이닝(Text Mining) 기술을 활용하여 대화 패턴을 정량적으로 분석하고, 참여자 간의 호감도를 객관적인 지표로 시각화해주는 PC 애플리케이션을 기획하게 되었습니다.

1.2 프로젝트 목표
1) 데이터 프라이버시 보장: 모든 분석 과정이 사용자 PC(Localhost) 내에서만 이루어지도록 하여 개인정보 유출 원천 차단.
2) 정량적/정성적 분석의 조화: 단순한 발화량 통계(정량)뿐만 아니라, 사용 단어의 뉘앙스를 파악하여 호감도(정성)를 수치화.
3) 직관적인 시각화: 복잡한 텍스트 데이터를 누구나 이해하기 쉬운 그래프와 요약 카드로 변환하여 제공.


2. 시스템 설계 및 구조 (System Architecture)


본 시스템은 일반적인 웹 서비스 아키텍처(Client-Server)를 차용하되, 이를 단일 실행 파일(.exe) 내에 패키징하여 로컬 환경에서 구동되도록 설계된 "Standalone Web-based Application"입니다.

2.1 시스템 아키텍처 상세
[ 사용자 PC (Windows Environment) ]
   |
   +-- [ KakaoLoveAnalysis.exe (PyInstaller Container) ]
         |
         +-- [ 1. Backend Layer (Python Runtime) ]
         |      |
         |      +-- Bottle Web Server: 경량 WSGI 서버로, 5000번 포트에서 REST API 수신
         |      +-- Parser Module: 비정형 텍스트 데이터를 정형 데이터(DataFrame)로 변환
         |      +-- NLP Engine: Kiwi(형태소 분석) + Scikit-learn(빈도 분석) + Scoring Algorithm
         |
         +-- [ 2. Frontend Layer (User Interface) ]
                |
                +-- React SPA: 사용자 인터페이스 로직 (Component, State Management)
                +-- Static Assets: 빌드된 HTML/CSS/JS 파일들이 백엔드를 통해 서빙됨

2.2 기술적 의사결정 (Technical Decisions)
1) 왜 Local Web Server 방식인가?
   PyQt나 Tkinter 같은 전통적인 데스크탑 GUI 프레임워크는 현대적이고 세련된 UI/UX를 구현하는 데 한계가 있습니다.
   React의 강력한 생태계(Recharts 등)를 활용하여 심미적으로 우수한 UI를 제공하면서도, Python의 강력한 데이터 분석 라이브러리를 그대로 활용하기 위해 "로컬 웹 서버 + 브라우저 UI" 구조를 채택했습니다.

2) 왜 Bottle 프레임워크인가?
   Django나 Flask는 기능이 방대하지만, 본 프로젝트처럼 단일 API 엔드포인트만 필요한 소규모 로컬 앱에는 오버헤드가 큽니다.
   Bottle은 단 하나의 파일(bottle.py)로 구성될 만큼 가볍고 의존성이 적어, PyInstaller로 패키징 시 실행 파일의 용량을 최소화할 수 있습니다.

2.3 데이터 흐름도 (Data Flow Diagram)
1. Input: 사용자가 카카오톡 '대화 내보내기' 기능을 통해 저장한 .txt 파일의 내용을 클립보드에 복사하여 애플리케이션 입력창에 붙여넣습니다.
2. Request: 프론트엔드에서 POST /api/analyze_text 요청을 로컬 백엔드로 전송합니다. 이때 데이터는 JSON 포맷({"text": "..."})으로 캡슐화됩니다.
3. Parsing & Preprocessing:
   백엔드는 정규표현식을 이용해 [날짜], [시간], [발신자], [메시지]를 추출합니다.
   '오전/오후'로 표기된 시간을 24시간제(HH:MM)로 변환하여 시계열 분석을 준비합니다.
4. Text Mining:
   추출된 메시지에서 불용어(Stopwords)를 제거하고, 형태소 분석기를 통해 명사(Noun)만 추출합니다.
   호감도 사전(Dictionary)과 대조하여 각 메시지의 감정 점수를 계산합니다.
5. Response: 분석된 통계 데이터(참여율, 키워드, 호감도 점수 등)를 JSON으로 반환합니다.
6. Visualization: 프론트엔드는 수신한 데이터를 바탕으로 차트와 요약 카드를 렌더링하여 사용자에게 보여줍니다.


3. 상세 구현 내용 및 사용 라이브러리


3.1 Backend (Python 3.x)
백엔드는 데이터 처리의 핵심 엔진으로, 다음과 같은 라이브러리들로 구성됩니다.

(1) Pandas (Data Manipulation)
   역할: 대화 데이터를 2차원 테이블 형태(DataFrame)로 구조화합니다.
   활용: value_counts()를 이용한 발화량 집계, dt.hour를 이용한 시간대별 그룹화 연산을 수행합니다. 대용량 텍스트 데이터도 효율적으로 메모리에 적재하고 처리할 수 있습니다.

(2) KiwiPiePy (Korean Morphological Analysis)
   역할: 한국어 자연어 처리의 핵심인 형태소 분석을 담당합니다.
   특징: 기존의 KoNLPy(Java 의존성 있음)와 달리 C++로 구현되어 있어 속도가 매우 빠르고, 설치 및 배포가 용이합니다. 본 프로젝트에서는 문장의 핵심 주제를 파악하기 위해 체언(명사) 추출에 주로 사용되었습니다.

(3) Scikit-learn (Machine Learning)
   역할: 텍스트의 특징 벡터화(Feature Vectorization)를 담당합니다.
   활용: CountVectorizer 클래스를 사용하여 전체 대화 코퍼스(Corpus)에서 단어의 등장 빈도(Term Frequency)를 계산하고, 상위 빈도 단어를 추출하여 '주요 대화 키워드'를 선정합니다.

(4) PyInstaller (Application Packaging)
   역할: 개발 환경(Python 스크립트)을 배포 환경(Windows 실행 파일)으로 변환합니다.
   설정: --onefile 옵션으로 단일 exe 파일을 생성하며, --add-data 옵션을 통해 React 빌드 결과물을 실행 파일 내부 리소스로 포함시킵니다.

3.2 Frontend (JavaScript / React)
프론트엔드는 사용자와 상호작용하는 인터페이스로, 최신 웹 기술을 사용하여 구현되었습니다.

(1) React & Vite
   역할: 컴포넌트 단위로 UI를 모듈화하여 개발 생산성을 높였습니다. Vite를 빌드 도구로 사용하여 최적화된 번들링을 수행합니다.

(2) Recharts
   역할: 데이터 시각화 라이브러리입니다. SVG 기반으로 차트를 렌더링하여 확대/축소 시에도 깨짐이 없으며, 애니메이션 효과를 통해 사용자 경험(UX)을 향상시킵니다.


4. 핵심 알고리즘 상세 (Algorithms)


4.1 멀티 포맷 파싱 알고리즘 (Multi-format Parsing)
카카오톡은 모바일(Android/iOS)과 PC(Windows/Mac) 버전마다, 그리고 OS 언어 설정마다 내보내기 형식이 조금씩 다릅니다. 이를 모두 수용하기 위해 계층적 파싱 전략을 사용했습니다.

Step 1: 날짜 라인 감지: --------------- 2024년 5월 20일 --------------- 패턴을 먼저 찾아 현재 처리 중인 날짜 컨텍스트를 갱신합니다.
Step 2: 메시지 헤더 감지:
  모바일: [이름] [오전/오후 00:00] 패턴
  PC: 2024. 5. 20. 오전 00:00, 이름 : 패턴
  위 두 가지 정규표현식을 순차적으로 적용하여 매칭되는 형식을 찾습니다.
Step 3: 멀티라인 병합: 정규표현식에 매칭되지 않는 줄은, 사용자가 엔터(줄바꿈)를 쳐서 보낸 긴 메시지의 일부로 간주하여 직전 메시지에 내용을 이어 붙입니다(Append).

4.2 룰 베이스 호감도 추론 (Rule-based Sentiment Analysis)
딥러닝 모델은 무겁고 학습 데이터가 필요하므로, 본 프로젝트에서는 언어학적 규칙 기반의 경량화된 알고리즘을 자체 설계했습니다.

감성 사전 구축:
  Strong Love (+18점): 사랑해, 좋아해, 보고싶다, 설레, 썸, 고백 등 (직접적인 애정 표현)
  Light Love (+10점): 귀여워, 예쁘다, 밥먹자, 영화, 데이트, 뭐해 등 (관심 및 만남 유도)
  Cold/Negative (-25점): 바빠, 피곤해, 귀찮아, 싫어, 됐어 등 (거절 및 회피)
점수 산출 로직:
  Total Score = Base(50) + (Strong_Count * 18) + (Light_Count * 10) - (Cold_Count * 25)
  최종 점수는 0~100점 사이로 클리핑(Clipping)되며, 점수 구간에 따라 4단계의 결과 메시지를 매핑합니다.


5. API 명세서 (API Specification)


5.1 텍스트 분석 API
Endpoint: POST /api/analyze_text
Content-Type: application/json
Request Body:
  
  {
    "text": "[김철수] [오전 10:00] 안녕?\n[이영희] [오전 10:01] 웅 안녕!..."
  }
  
Response Body:
  
  {
    "participation": [
      {"sender": "김철수", "count": 120, "ratio": 40.0},
      {"sender": "이영희", "count": 180, "ratio": 60.0}
    ],
    "keywords": [
      {"word": "영화", "count": 15},
      {"word": "저녁", "count": 8}
    ],
    "interestScore": 85,
    "interestLabel": "저 몰래 두분 이미 사귀고 있죠? 💘",
    "topic": "상당히 달달한 분위기!",
    "summary": "대화에 애정 표현이나 만남 제안이 많습니다...",
    "timeDistribution": [
      {"hour": 0, "count": 5},
      {"hour": 1, "count": 0},
      ... (0~23시 데이터)
    ]
  }
  


6. 실행 화면 및 사용법


(이곳에는 실제 보고서 작성 시 캡쳐 이미지를 삽입합니다)

[그림 1. 메인 화면]
프로그램을 실행하면 나타나는 첫 화면입니다. 직관적인 UI를 위해 불필요한 메뉴를 제거하고, 중앙에 대화 입력창을 크게 배치했습니다. 사용자는 별도의 로그인 없이 즉시 서비스를 이용할 수 있습니다.

[그림 2. 분석 결과 - 대시보드]
분석이 완료되면 화면이 전환되며 대시보드가 나타납니다. 상단에는 가장 중요한 '호감도 점수'와 '한 줄 요약'이 카드 형태로 표시되어 결론부터 빠르게 확인할 수 있습니다.

[그림 3. 분석 결과 - 상세 차트]
스크롤을 내리면 참여자별 대화 비중을 보여주는 막대그래프와, 시간대별 대화 패턴을 보여주는 꺾은선 그래프가 나타납니다. 이를 통해 누가 더 적극적으로 대화를 이끌어가는지, 주로 언제 연락하는지 등의 행동 패턴을 파악할 수 있습니다.


7. 결론 및 향후 과제


7.1 결론
본 프로젝트를 통해 비정형 텍스트 데이터인 카카오톡 대화 내용을 정량적/정성적으로 분석하여 사용자에게 가치 있는 정보를 제공하는 시스템을 성공적으로 구현했습니다. 특히 Python의 강력한 분석 기능과 React의 유려한 UI를 결합하고, 이를 단일 실행 파일로 패키징함으로써 '성능', '심미성', '편의성', '보안성'이라는 네 마리 토끼를 모두 잡을 수 있었습니다.

7.2 한계점 및 향후 과제
문맥 파악의 한계: 현재의 키워드 기반 분석은 "사랑해"라는 단어가 비꼬는 상황에서 쓰였는지, 진심인지 문맥(Context)을 완벽히 파악하지 못하는 한계가 있습니다. 향후 BERT와 같은 딥러닝 언어 모델을 경량화하여 탑재한다면 이를 개선할 수 있을 것입니다.
다양한 메신저 지원: 현재는 카카오톡만 지원하지만, 추후 라인(Line), 인스타그램 DM 등의 내보내기 형식도 지원하도록 파서(Parser)를 확장할 계획입니다.
